{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /opt/homebrew/lib/python3.11/site-packages (1.3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress, please wait...\n",
      "Completing task 1 out of 6...\n",
      "Completing task 2 out of 6...\n",
      "Completing task 3 out of 6...\n",
      "Completing task 4 out of 6...\n",
      "Completing task 5 out of 6...\n",
      "Completing task 6 out of 6...\n",
      "Done! File is at scores_and_ids.json.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "URL = \"https://api.sorare.com/federation/graphql\"\n",
    "APIKEY = \"834eaada2776d187c02c7ac077a3a13bb019cc47f883c67335b5dece3ec3327a5d6cd8b2ce7369b9da511b5648a6e915c950857a6231088b121b1690824sr128\"\n",
    "\n",
    "def check_cache(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        return json.load(open(filename))\n",
    "\n",
    "def get_players(QUERY, quiet):\n",
    "    js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': QUERY}).text)\n",
    "    if 'error' in js_obj:\n",
    "        return [], \"\"\n",
    "    list_of_players, next_cursor = [player['node']['slug'] for player in js_obj['data']['tokens']['allNfts']['edges']], js_obj['data']['tokens']['allNfts']['pageInfo']['endCursor']\n",
    "    if not quiet: print(list_of_players)\n",
    "    return list_of_players, next_cursor\n",
    "\n",
    "def get_query_with_start_cursor(quiet, STARTCURSOR=\"\"):\n",
    "    if STARTCURSOR == \"\":\n",
    "        QUERY = \"\"\"{\n",
    "            tokens {\n",
    "                allNfts(sport: [BASEBALL], rarities: [super_rare]) {\n",
    "                edges {\n",
    "                    node {\n",
    "                    slug\n",
    "                    }\n",
    "                }\n",
    "                pageInfo {\n",
    "                    hasNextPage\n",
    "                    startCursor\n",
    "                    endCursor\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "        }\"\"\"\n",
    "        return get_players(QUERY, quiet=quiet)\n",
    "    QUERY = \"\"\"{\n",
    "        tokens {\n",
    "            allNfts(sport: [BASEBALL], rarities: [super_rare], after:\"%s\") {\n",
    "            edges {\n",
    "                node {\n",
    "                slug\n",
    "                }\n",
    "            }\n",
    "            pageInfo {\n",
    "                hasNextPage\n",
    "                startCursor\n",
    "                endCursor\n",
    "            }\n",
    "            }\n",
    "        }\n",
    "    }\"\"\" % (STARTCURSOR)\n",
    "    return get_players(QUERY, quiet=quiet)\n",
    "\n",
    "def process_player_slugs(slug):\n",
    "    return ['-'.join(player.split('-')[:-3]) for player in slug]\n",
    "\n",
    "def populate_players(save=True, quiet=False):\n",
    "    '''\n",
    "    One-run function. Iterates through cards of high rarity to minimize duplicates, and adds those to a player register for post-processing in the bot.\n",
    "\n",
    "    save: Saves output to a separate file on the disk.\n",
    "    quiet: Suppresses output from API calls\n",
    "    '''\n",
    "\n",
    "    cache = check_cache(\"./players-slug.json\")\n",
    "    if cache: return cache\n",
    "\n",
    "    players = []\n",
    "    print(\"In progress, please wait...\")\n",
    "    listOfPlayers = get_query_with_start_cursor(quiet=quiet)\n",
    "    while listOfPlayers[1]:\n",
    "        players.extend(process_player_slugs(listOfPlayers[0]))\n",
    "        listOfPlayers = get_query_with_start_cursor(listOfPlayers[1], quiet=quiet)\n",
    "    players = list(set(players))\n",
    "    \n",
    "    filtered_player_arr = json.dumps(players, indent=4)\n",
    "    if save:\n",
    "        with open(\"players-slug.json\", \"w\") as out:\n",
    "            out.write(filtered_player_arr)\n",
    "    return players\n",
    "\n",
    "def filter_names_that_are_present_in_2023(sorarejson):\n",
    "    print(\"Filtering names that have only played in 2023...\")\n",
    "    to_keep = json.load(open(sorarejson))\n",
    "    sorare_arr = [unidecode(slug + \"-2023-limited-1\") for slug in json.load(open(sorarejson))]\n",
    "    start, result = 0, []\n",
    "    while start < len(sorare_arr):\n",
    "        SLUG_QUERY = \"\"\"{\n",
    "            baseballCards(slugs: %s) {\n",
    "                player {\n",
    "                    displayName\n",
    "                }\n",
    "            }\n",
    "        }\"\"\" % (json.dumps(sorare_arr[start:start + 50]))\n",
    "        js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': SLUG_QUERY}).text)\n",
    "        result.extend([unidecode(_[\"player\"][\"displayName\"]).lower() for _ in js_obj[\"data\"][\"baseballCards\"]])\n",
    "        start += 50\n",
    "    first_ctr, second_ctr = 0, 0\n",
    "    final_res = []\n",
    "    while first_ctr < len(sorare_arr) and second_ctr < len(result):\n",
    "        if result[second_ctr].split(\" \")[-1] in sorare_arr[first_ctr] or result[second_ctr].split(\" \")[-2] in sorare_arr[first_ctr]:\n",
    "            final_res.append(first_ctr)\n",
    "            second_ctr += 1\n",
    "        first_ctr += 1\n",
    "    return [to_keep[id] for id in final_res]\n",
    "\n",
    "def generate_names(save=True, sorarejson=\"./players-slug.json\"):\n",
    "    '''\n",
    "    Generates name objects from the slug of a player's Sorare ID.\n",
    "\n",
    "    save: Saves output to a separate file on the disk.\n",
    "    sorarejson: JSON file with Sorare slug data\n",
    "    '''\n",
    "    cache = check_cache(\"./players-names-slug.json\")\n",
    "    if cache: return cache\n",
    "\n",
    "    sorare_arr = filter_names_that_are_present_in_2023(sorarejson)\n",
    "    sorare_arr_with_limited_rarity = [slug + \"-2023-limited-1\" for slug in sorare_arr]\n",
    "    print(\"In progress, please wait...\")\n",
    "\n",
    "    start, player_arr = 0, []\n",
    "    while start < len(sorare_arr):\n",
    "        SLUG_QUERY = \"\"\"{\n",
    "            baseballPlayers(slugs: %s) {\n",
    "                firstName\n",
    "                lastName\n",
    "                positions\n",
    "            }\n",
    "            baseballCards(slugs: %s) {\n",
    "                player {\n",
    "                    displayName\n",
    "                }\n",
    "            }\n",
    "        }\"\"\" % (json.dumps(sorare_arr[start:start + 50]), json.dumps(sorare_arr_with_limited_rarity[start:start + 50]))\n",
    "        js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': SLUG_QUERY}).text)\n",
    "\n",
    "        first_result, second_result = js_obj[\"data\"][\"baseballPlayers\"], [unidecode(_[\"player\"][\"displayName\"].lower()) for _ in js_obj[\"data\"][\"baseballCards\"]]\n",
    "        for obj in first_result: obj[\"firstName\"], obj[\"lastName\"] = unidecode(obj[\"firstName\"].lower()), unidecode(obj[\"lastName\"].lower())\n",
    "        player_arr.extend(zip(first_result, second_result, sorare_arr[start:start + 50]))\n",
    "        print(\"Players\", start, \"to\", start + 50, \"added.\")\n",
    "        start += 50\n",
    "    print(\"Length of player-name-matched array (active players):\", len(player_arr))\n",
    "\n",
    "    dumped_player_arr = json.dumps(player_arr, indent=4)\n",
    "    if save:\n",
    "        with open(\"players-names-slug.json\", \"w\") as out:\n",
    "            out.write(dumped_player_arr)\n",
    "    print(\"Done! File is at players-name-slug.json.\" if save else \"Done!\")\n",
    "    \n",
    "    return player_arr\n",
    "\n",
    "def contains_some_match(playName, fullPlayer):\n",
    "    '''\n",
    "    Attempts to determine if some match (fuzzy) exists between the player's full name and the name the player uses for lineups/etc.\n",
    "\n",
    "    playName: name given by MLB registry: \"kris bryant\"\n",
    "    fullPlayer: player list retrieved from post-processing (Sorare side). For example:\n",
    "        [\n",
    "            {\n",
    "                \"firstName\": \"kristopher\",\n",
    "                \"lastName\": \"bryant\",\n",
    "                \"positions\": [\n",
    "                    \"OUTFIELD\",\n",
    "                    \"DESIGNATED_HITTER\"\n",
    "                ]\n",
    "            },\n",
    "            \"kris bryant\",\n",
    "            \"kris-bryant-19920104\"\n",
    "        ]\n",
    "    '''\n",
    "    # Check first name\n",
    "    checkOne, checkTwo = False, False\n",
    "\n",
    "    first_name = playName.split(\" \")[0]\n",
    "    if first_name in fullPlayer[1] or first_name in fullPlayer[2] or first_name in fullPlayer[0][\"firstName\"]:\n",
    "        checkOne = True\n",
    "    last_name = playName.split(\" \")[-1]\n",
    "    if last_name in fullPlayer[1] or last_name in fullPlayer[2] or last_name in fullPlayer[0][\"lastName\"]:\n",
    "        checkTwo = True\n",
    "\n",
    "    return checkOne and checkTwo\n",
    "\n",
    "\n",
    "\n",
    "def compare_names(save=True, mlbjson=\"../sorarebot/playerslastdecade.json\", sorarejson=\"./players-name-slug.json\"):\n",
    "    '''\n",
    "    Attempts to match names from Sorare Player Cards to those in the official baseball registry. Also classifies valid-matching players into their respective fielding categories.\n",
    "\n",
    "    save: Saves output to a separate file on the disk.\n",
    "    ...json: Respective JSON files for data\n",
    "    '''\n",
    "\n",
    "    cache = check_cache(\"./players-matched-registry.json\")\n",
    "    if cache: return cache\n",
    "\n",
    "    # Load information into a dictionary\n",
    "    mlb_registry_arr, mlb_registry = json.load(open(mlbjson)), dict()\n",
    "    for player in mlb_registry_arr:\n",
    "        mlb_registry[unidecode(player[\"name_first\"] + \" \" + player[\"name_last\"]).lower()] = player[\"key_mlbam\"]\n",
    "    sorare_arr = generate_names(sorarejson=sorarejson)\n",
    "\n",
    "    print(\"Please wait, matching players from official registry to Sorare DB...\")\n",
    "    final_registry = dict() # Dict of lists [slug, positions-played object]\n",
    "    for idx, player in enumerate(sorare_arr):\n",
    "        # Attempt complete matching first.\n",
    "        name = player[1]\n",
    "        if name in mlb_registry:\n",
    "            # Complete match found.\n",
    "            final_registry[name] = [player[2], player[0][\"positions\"], mlb_registry[name]]\n",
    "        else:\n",
    "            for element in mlb_registry:\n",
    "                if contains_some_match(element, player):\n",
    "                    final_registry[element] = [player[2], player[0][\"positions\"], mlb_registry[element]]\n",
    "                    break\n",
    "        \n",
    "        if idx % 50 == 0:\n",
    "            print(idx, \"players processed so far.\")\n",
    "    \n",
    "    print(\"Successful!\", len(final_registry), \"players were successfully classified and matched.\")\n",
    "\n",
    "    dumped_registry = json.dumps(final_registry, indent=4)\n",
    "    if save:\n",
    "        with open(\"players-matched-registry.json\", \"w\") as out:\n",
    "            out.write(dumped_registry)\n",
    "    print(\"Done! File is at players-matched-registry.json.\" if save else \"Done!\")\n",
    "    return final_registry\n",
    "\n",
    "def separate_players_into_positions(save=True, filename=\"./players-matched-registry.json\"):\n",
    "\n",
    "    cache = check_cache(\"./players-filtered-result.json\")\n",
    "    if cache: return cache\n",
    "\n",
    "    registry = json.load(open(filename))\n",
    "    result = [dict() for _ in range(6)] # OF, IF, DH, C, SP, RP. Prefer OF > IF > DH > C, RP > SP\n",
    "    for player in registry:\n",
    "        # registry[player][1] is position object\n",
    "        if \"RELIEF_PITCHER\" in registry[player][1]:\n",
    "            result[5][player] = [registry[player][0], registry[player][2]]\n",
    "        elif \"STARTING_PITCHER\" in registry[player][1]:\n",
    "            result[4][player] = [registry[player][0], registry[player][2]]\n",
    "        elif \"OUTFIELD\" in registry[player][1]:\n",
    "            result[0][player] = [registry[player][0], registry[player][2]]\n",
    "        elif \"FIRST_BASE\" in registry[player][1] or \"SECOND_BASE\" in registry[player][1] or \"THIRD_BASE\" in registry[player][1] or \"SHORTSTOP\" in registry[player][1]:\n",
    "            result[1][player] = [registry[player][0], registry[player][2]]\n",
    "        elif \"DESIGNATED_HITTER\" in registry[player][1]:\n",
    "            result[2][player] = [registry[player][0], registry[player][2]]\n",
    "        elif \"CATCHER\" in registry[player][1]:\n",
    "            result[3][player] = [registry[player][0], registry[player][2]]\n",
    "\n",
    "    dumped_result = json.dumps(result, indent=4)\n",
    "    if save:\n",
    "        with open(\"players-filtered-result.json\", \"w\") as out:\n",
    "            out.write(dumped_result)\n",
    "    print(\"Done! File is at players-filtered-result.json.\" if save else \"Done!\")\n",
    "    return result\n",
    "    \n",
    "def search_values_for_players(save=True, filename=\"./players-filtered-result.json\"):\n",
    "\n",
    "    cache = check_cache(\"./scores_and_ids.json\")\n",
    "    if cache: return cache\n",
    "    \n",
    "    filtered_result = json.load(open(filename))\n",
    "    named_result = [dict() for _ in range(6)]\n",
    "\n",
    "    print(\"In progress, please wait...\")\n",
    "\n",
    "    for idx, category in enumerate(filtered_result):\n",
    "        print(\"Completing task\", idx + 1, \"out of 6...\")\n",
    "        if idx < 4: batter = True\n",
    "        else: batter = False\n",
    "\n",
    "        ctr = 0\n",
    "        slugs = [(category[player][0] + \"-2023-limited-1\", player) for player in category]\n",
    "        while ctr < len(category):\n",
    "            # Run GraphQL query here\n",
    "            if batter:\n",
    "                QUERY = \"\"\"{\n",
    "                    baseballCards(slugs: %s) {\n",
    "                        player {\n",
    "                            currentSeasonAverageScore{\n",
    "                                batting\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \"\"\" % (json.dumps([_[0] for _ in slugs[ctr:ctr + 50]]))\n",
    "                js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': QUERY}).text)\n",
    "                for curr, value in enumerate(js_obj[\"data\"][\"baseballCards\"]):\n",
    "                    named_result[idx][slugs[ctr + curr][1]] = [value[\"player\"][\"currentSeasonAverageScore\"][\"batting\"], category[slugs[ctr + curr][1]][1], category[slugs[ctr + curr][1]][0]]\n",
    "            else:\n",
    "                QUERY = \"\"\"{\n",
    "                    baseballCards(slugs: %s) {\n",
    "                        player {\n",
    "                            currentSeasonAverageScore{\n",
    "                                pitching\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \"\"\" % (json.dumps([_[0] for _ in slugs[ctr:ctr + 50]]))\n",
    "                js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': QUERY}).text)\n",
    "                for curr, value in enumerate(js_obj[\"data\"][\"baseballCards\"]):\n",
    "                    named_result[idx][slugs[ctr + curr][1]] = [value[\"player\"][\"currentSeasonAverageScore\"][\"pitching\"], category[slugs[ctr + curr][1]][1], category[slugs[ctr + curr][1]][0]]\n",
    "            ctr += 50\n",
    "    \n",
    "    scores_and_ids = json.dumps(named_result, indent=4)\n",
    "    if save:\n",
    "        with open(\"scores_and_ids.json\", \"w\") as out:\n",
    "            out.write(scores_and_ids)\n",
    "    print(\"Done! File is at scores_and_ids.json.\" if save else \"Done!\")\n",
    "    return named_result\n",
    "\n",
    "search_values_for_players()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_med(token_prices):\n",
    "    if len(token_prices) & 1:\n",
    "        med_ind = len(token_prices) // 2\n",
    "        return token_prices[med_ind]\n",
    "    else: \n",
    "        med_ind = len(token_prices) // 2 - 1\n",
    "        return (token_prices[med_ind] + token_prices[med_ind + 1]) / 2\n",
    "\n",
    "import time\n",
    "def retrieve_med_price(save=True, filename=\"./scores_and_ids.json\", rarity=\"limited\"):\n",
    "    '''\n",
    "    Function to retrieve median price of player given slug (for the purposes of practicality, we are only dealing with limited cards but the rarity can be tuned).\n",
    "\n",
    "    This calls the API for each individual player (1000+), so without an API key, this will not successfully run.\n",
    "    '''\n",
    "    players = json.load(open(filename))\n",
    "    after_med_prices_injected = [dict()]\n",
    "    \n",
    "    print(\"Please wait, in progress...\")\n",
    "\n",
    "    for idx, each in enumerate(players):\n",
    "        # each is a dictionary of players, as previously clustered by position\n",
    "        print(\"Completing task\", idx + 1, \"out of\", len(players), \"...\")\n",
    "        for pid, player in enumerate(each):\n",
    "            QUERY = '''\n",
    "            {\n",
    "                tokens {\n",
    "                    tokenPrices(rarity: %s, playerSlug: \"%s\", collection: BASEBALL) {\n",
    "                        amountInFiat {\n",
    "                            usd\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            ''' % (rarity, each[player][-1])\n",
    "            js_obj = json.loads(requests.post(URL, headers={\"APIKEY\": APIKEY}, json={'query': QUERY}).text)\n",
    "            token_prices = [priceObj[\"amountInFiat\"][\"usd\"] for priceObj in js_obj[\"data\"][\"tokens\"][\"tokenPrices\"]]\n",
    "            after_med_prices_injected[idx][player] = each[player][:-1] + [calc_med(token_prices)]\n",
    "            time.sleep(0.1) # Prevent API overload\n",
    "            print(pid + 1, \"of\", len(each), \"completed.\")\n",
    "        after_med_prices_injected.append(dict())\n",
    "    \n",
    "    after_med_prices_injected.pop()\n",
    "\n",
    "    updated_scores_and_ids = json.dumps(after_med_prices_injected, indent=4)\n",
    "    if save:\n",
    "        with open(\"u_scores_and_ids.json\", \"w\") as out:\n",
    "            out.write(updated_scores_and_ids)\n",
    "    print(\"Done! File is at u_scores_and_ids.json.\" if save else \"Done!\")\n",
    "    return after_med_prices_injected\n",
    "\n",
    "retrieve_med_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
